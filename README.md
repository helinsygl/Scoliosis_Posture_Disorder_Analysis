# Scoliosis Analysis Project

Advanced deep learning-based scoliosis analysis system. Extracts pose keypoints from RGB video files using MediaPipe and performs scoliosis/normal classification using LSTM/Transformer models.

## ğŸ“ Project Structure

```
scoliosis_project/
â”‚
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ scoliosis/
â”‚   â”‚   â”œâ”€â”€ front/
â”‚   â”‚   â””â”€â”€ side/
â”‚   â”œâ”€â”€ normal/
â”‚   â”‚   â”œâ”€â”€ front/
â”‚   â”‚   â””â”€â”€ side/
â”‚   â””â”€â”€ raw_videos/          # Original videos (optional)
â”‚
â”œâ”€â”€ keypoints/               # Extracted pose keypoint NPY files
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract_keypoints.py # MediaPipe keypoint extraction
â”‚   â”œâ”€â”€ dataset.py           # Keypoint dataset loader
â”‚   â”œâ”€â”€ model.py             # LSTM / Transformer models
â”‚   â”œâ”€â”€ train.py             # Training script
â”‚   â”œâ”€â”€ evaluate.py          # Evaluation + metrics
â”‚   â”œâ”€â”€ predict.py           # Single video prediction
â”‚   â””â”€â”€ utils.py             # Utility functions
â”‚
â”œâ”€â”€ saved_models/
â”‚   â””â”€â”€ best_model.pth
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ EDA.ipynb            # Exploratory analysis, visualizations
â”‚
â”œâ”€â”€ requirements.txt
â”‚
â””â”€â”€ README.md
```

## ğŸš€ Installation

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Prepare Dataset Structure

Organize your videos in the following structure:

```
dataset/
â”œâ”€â”€ normal/
â”‚   â”œâ”€â”€ front/    # Normal - front view videos
â”‚   â””â”€â”€ side/     # Normal - side view videos
â””â”€â”€ scoliosis/
    â”œâ”€â”€ front/    # Scoliosis - front view videos
    â””â”€â”€ side/     # Scoliosis - side view videos
```

**Supported video formats:** AVI, MP4, MOV, MKV, WMV, FLV

## ğŸ“Š Step-by-Step Usage Guide

### Step 1: Extract Keypoints from Videos

Extract pose keypoints from all videos in your dataset:

```bash
cd /kullanici_yedek/helin.saygili/Scoliosis_Posture_Disorder_Analysis
python3 src/extract_keypoints.py --dataset_root dataset --output_dir keypoints
```

**What this does:**
- Scans all videos in `dataset/normal/` and `dataset/scoliosis/` folders
- Extracts 33 pose keypoints per frame using MediaPipe
- Saves keypoints as `.npy` files in `keypoints/` directory
- Creates `metadata.json` with video information

**Incremental Mode (Default - Time Saving):**

By default, the script runs in **incremental mode**, which means:
- âœ… Only processes **new videos** that don't have keypoint files yet
- âœ… Skips videos that are already processed
- âœ… Updates metadata automatically
- â±ï¸ **Saves significant time** when adding new videos to dataset

**First run (all videos):**
```bash
python3 src/extract_keypoints.py --dataset_root dataset --output_dir keypoints
```

**Adding new videos (incremental - default):**
```bash
# After adding new videos to dataset, run again - only new ones will be processed
python3 src/extract_keypoints.py --dataset_root dataset --output_dir keypoints
# or explicitly:
python3 src/extract_keypoints.py --dataset_root dataset --output_dir keypoints --incremental
```

**Force re-processing all videos:**
```bash
# Process all videos again (even if keypoints exist)
python3 src/extract_keypoints.py --dataset_root dataset --output_dir keypoints --force
```

**Expected output (incremental mode):**
```
ğŸ” Video dosyalarÄ± aranÄ±yor...
ğŸ“¹ Toplam 225 video bulundu
  Normal - Front: 57
  Normal - Side: 56
  Scoliosis - Front: 56
  Scoliosis - Side: 56
ğŸ“‚ Mevcut 219 keypoint dosyasÄ± bulundu
ğŸ”„ Incremental mode: Sadece yeni videolar iÅŸlenecek
â­ï¸  219 video atlandÄ± (zaten iÅŸlenmiÅŸ)
ğŸ†• 6 yeni video iÅŸlenecek
Keypoint Ã§Ä±karÄ±mÄ±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [02:15<00:00, 22.5s/video]

âœ… 6 yeni video iÅŸlendi
ğŸ“Š Toplam 225 baÅŸarÄ±lÄ± keypoint dosyasÄ±
ğŸ“ Keypoint'ler kaydedildi: keypoints
```

**Expected output (first run):**
```
ğŸ” Video dosyalarÄ± aranÄ±yor...
ğŸ“¹ Toplam 219 video bulundu
  Normal - Front: 55
  Normal - Side: 54
  Scoliosis - Front: 55
  Scoliosis - Side: 55
ğŸ”„ Incremental mode: Sadece yeni videolar iÅŸlenecek
ğŸ†• 219 yeni video iÅŸlenecek
Keypoint Ã§Ä±karÄ±mÄ±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 219/219 [45:30<00:00, 12.45s/video]

âœ… 219 yeni video iÅŸlendi
ğŸ“Š Toplam 219 baÅŸarÄ±lÄ± keypoint dosyasÄ±
ğŸ“ Keypoint'ler kaydedildi: keypoints
```

**Note:** 
- This step may take 1-3 hours for first run depending on the number and length of videos
- Incremental mode significantly reduces time when adding new videos (only processes new ones)
- Runs on CPU (MediaPipe doesn't use GPU)

---

### Step 2: Train the Model

Train the model using extracted keypoints:

```bash
python3 src/train.py \
    --keypoints_dir keypoints \
    --model_type advanced_lstm \
    --epochs 100 \
    --lr 0.001 \
    --batch_size 16 \
    --device cuda \
    --save_dir saved_models \
    --model_name best_model
```

**Model Types:**
- `advanced_lstm`: Advanced LSTM with bidirectional layers and attention mechanism (Recommended)
- `transformer`: Transformer encoder model
- `hybrid`: Hybrid LSTM + Transformer model

**GPU Training (Recommended):**
```bash
python3 src/train.py \
    --keypoints_dir keypoints \
    --model_type advanced_lstm \
    --epochs 100 \
    --lr 0.001 \
    --batch_size 16 \
    --device cuda
```

**CPU Training (if no GPU):**
```bash
python3 src/train.py \
    --keypoints_dir keypoints \
    --model_type advanced_lstm \
    --epochs 100 \
    --lr 0.001 \
    --batch_size 8 \
    --device cpu
```

**Expected output:**
```
ğŸ”§ Device: cuda
ğŸ“Š Dataset yÃ¼klendi:
  Train: 175 Ã¶rnek
  Test: 44 Ã¶rnek
  Normal: 110 Ã¶rnek
  Scoliosis: 109 Ã¶rnek
ğŸ“Š Model parametreleri: 1,234,567

ğŸš€ EÄŸitim baÅŸlÄ±yor...
  Model: AdvancedLSTM
  Epochs: 100
  Learning rate: 0.001
  Device: cuda

Epoch 1/100
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:30<00:00, loss=0.6234, acc=65.23%]
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00]
Train Loss: 0.6234, Train Acc: 65.23%
Val Loss: 0.5891, Val Acc: 68.18%
âœ… Best model kaydedildi! (Val Acc: 68.18%)

...

âœ… EÄŸitim tamamlandÄ±!
  Best validation accuracy: 87.50%
  Model kaydedildi: saved_models/best_model.pth
```

**Training parameters:**
- `--epochs`: Number of training epochs (default: 100)
- `--lr`: Learning rate (default: 0.001)
- `--batch_size`: Batch size (default: 8, use 16-32 for GPU)
- `--device`: Device to use (`cuda` or `cpu`)

---

### Step 3: Evaluate the Model

Evaluate the trained model on the test set:

```bash
python3 src/evaluate.py \
    --keypoints_dir keypoints \
    --model_path saved_models/best_model.pth \
    --model_type advanced_lstm \
    --output_dir results \
    --device cuda
```

**Expected output:**
```
ğŸ”§ Device: cuda
ğŸ“‚ Checkpoint yÃ¼klendi: saved_models/best_model.pth
  Epoch: 95, Val Acc: 87.50%

ğŸ”® Model deÄŸerlendirmesi baÅŸlÄ±yor...
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:10<00:00]

==================================================
ğŸ“Š DEÄERLENDÄ°RME METRÄ°KLERÄ°
==================================================

ğŸ¯ Genel Metrikler:
  Accuracy:  0.8750
  Precision: 0.8765
  Recall:    0.8750
  F1-Score:  0.8752

ğŸ“ˆ SÄ±nÄ±f BazlÄ± Metrikler:
  Normal:
    Precision: 0.8800
    Recall:    0.8800
    F1-Score:  0.8800
  Scoliosis:
    Precision: 0.8700
    Recall:    0.8700
    F1-Score:  0.8700

ğŸ”¢ Confusion Matrix:
              Predicted
              Normal  Scoliosis
  Actual Normal      22        3
         Scoliosis    3       16
==================================================

âœ… SonuÃ§lar kaydedildi:
  Metrikler: results/evaluation_metrics.json
  DetaylÄ± sonuÃ§lar: results/detailed_results.json
```

---

### Step 4: Predict on New Videos

Use the trained model to predict scoliosis/normal on new test videos:

#### Single Video Prediction

```bash
python3 src/predict.py \
    --model_path saved_models/best_model.pth \
    --model_type advanced_lstm \
    --video test_video.mp4 \
    --device cuda
```

**Expected output:**
```
ğŸ”§ Device: cuda
  GPU: NVIDIA GeForce RTX 3090
ğŸ“‚ Model yÃ¼kleniyor: saved_models/best_model.pth
ğŸ“‚ Checkpoint yÃ¼klendi: saved_models/best_model.pth
  Epoch: 95, Val Acc: 87.50%

ğŸ¬ Video iÅŸleniyor: test_video.mp4
Ä°ÅŸlenen frame sayÄ±sÄ±: 30
Ä°ÅŸlenen frame sayÄ±sÄ±: 60
...

==================================================
ğŸ“Š TAHMÄ°N SONUCU
==================================================
Video: test_video.mp4
Tahmin: Skolyoz
GÃ¼ven SkorlarÄ±:
  Normal:   0.1234 (12.34%)
  Skolyoz:  0.8766 (87.66%)
Frame sayÄ±sÄ±: 150
==================================================
```

#### Batch Prediction (Multiple Videos)

```bash
python3 src/predict.py \
    --model_path saved_models/best_model.pth \
    --model_type advanced_lstm \
    --video_dir test_videos/ \
    --output results/predictions.json \
    --device cuda
```

**Save prediction results to JSON:**
```bash
python3 src/predict.py \
    --model_path saved_models/best_model.pth \
    --model_type advanced_lstm \
    --video test_video.mp4 \
    --output results/prediction_result.json \
    --device cuda
```

**JSON output format:**
```json
{
  "video_path": "test_video.mp4",
  "prediction": "Scoliosis",
  "prediction_class": 1,
  "confidence": {
    "Normal": 0.1234,
    "Scoliosis": 0.8766
  },
  "raw_probabilities": [0.1234, 0.8766],
  "num_frames": 150
}
```

---

## ğŸ¯ Features

- âœ… **MediaPipe Pose Detection**: 33 keypoint extraction per frame
- âœ… **Incremental Processing**: Only processes new videos (saves time when adding data)
- âœ… **Advanced Models**: LSTM, Transformer, Hybrid architectures
- âœ… **Multi-view Support**: Front and side view support
- âœ… **Comprehensive Metrics**: Accuracy, Precision, Recall, F1-Score, Confusion Matrix
- âœ… **Early Stopping**: Prevents overfitting
- âœ… **GPU Support**: CUDA acceleration
- âœ… **Batch Processing**: Process multiple videos efficiently

## ğŸ“ˆ Metrics and Results

Evaluation results are saved in `results/` directory:
- `evaluation_metrics.json`: Overall metrics (accuracy, precision, recall, F1)
- `detailed_results.json`: Detailed prediction results for each sample

## ğŸ”§ Advanced Usage

### Custom Model Parameters

You can customize model parameters in `src/model.py`:

```python
model = build_model(
    model_type="advanced_lstm",
    input_dim=99,
    hidden_dim=256,
    num_layers=3,
    dropout=0.3,
    bidirectional=True,
    use_attention=True
)
```

### Adjust Training Parameters

```bash
# Larger batch size for GPU
python3 src/train.py --batch_size 32 --lr 0.0005

# More epochs
python3 src/train.py --epochs 200

# Different learning rate
python3 src/train.py --lr 0.0001
```

### Check GPU Availability

```bash
python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"
```

## ğŸ“ Notes

- **Keypoint extraction** may take 1-3 hours depending on video count and length (runs on CPU)
- **GPU usage is highly recommended** for training (significantly reduces training time)
- Model checkpoints are saved in `saved_models/` directory
- Best model is automatically saved based on validation accuracy
- Training history is saved as JSON for visualization

## ğŸš€ Quick Start Commands

**Complete workflow:**

```bash
# 1. Extract keypoints (first time - all videos)
python3 src/extract_keypoints.py --dataset_root dataset --output_dir keypoints

# 1b. Add new videos (incremental - only new ones processed)
python3 src/extract_keypoints.py --dataset_root dataset --output_dir keypoints

# 2. Train model
python3 src/train.py --keypoints_dir keypoints --model_type advanced_lstm --epochs 100 --device cuda

# 3. Evaluate model
python3 src/evaluate.py --keypoints_dir keypoints --model_path saved_models/best_model.pth --model_type advanced_lstm

# 4. Predict on new video
python3 src/predict.py --model_path saved_models/best_model.pth --model_type advanced_lstm --video test_video.mp4 --device cuda
```

## ğŸ¤ Contributing

This project is under active development. Feel free to open issues for suggestions or improvements.

## ğŸ“„ License

This project is for research purposes.